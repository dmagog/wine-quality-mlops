[2025-05-27T12:30:00.295+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models manual__2025-05-27T12:29:58.357761+00:00 [queued]>
[2025-05-27T12:30:00.305+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models manual__2025-05-27T12:29:58.357761+00:00 [queued]>
[2025-05-27T12:30:00.305+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2025-05-27T12:30:00.316+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): train_and_log_models> on 2025-05-27 12:29:58.357761+00:00
[2025-05-27T12:30:00.324+0000] {standard_task_runner.py:60} INFO - Started process 3297 to run task
[2025-05-27T12:30:00.330+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'train_ml_models', 'train_and_log_models', 'manual__2025-05-27T12:29:58.357761+00:00', '--job-id', '55', '--raw', '--subdir', 'DAGS_FOLDER/train_models.py', '--cfg-path', '/tmp/tmp9c5gqa2n']
[2025-05-27T12:30:00.337+0000] {standard_task_runner.py:88} INFO - Job 55: Subtask train_and_log_models
[2025-05-27T12:30:00.461+0000] {task_command.py:423} INFO - Running <TaskInstance: train_ml_models.train_and_log_models manual__2025-05-27T12:29:58.357761+00:00 [running]> on host f0b48d92db9c
[2025-05-27T12:30:00.556+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='train_ml_models' AIRFLOW_CTX_TASK_ID='train_and_log_models' AIRFLOW_CTX_EXECUTION_DATE='2025-05-27T12:29:58.357761+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-27T12:29:58.357761+00:00'
[2025-05-27T12:30:02.324+0000] {logging_mixin.py:188} INFO - üß™ –í—ã–ø–æ–ª–Ω—è–µ–º dvc pull...
[2025-05-27T12:30:02.329+0000] {logging_mixin.py:188} INFO - STDOUT: Everything is up to date.
[2025-05-27T12:30:02.329+0000] {logging_mixin.py:188} INFO - STDERR: 
[2025-05-27T12:30:02.371+0000] {file_store.py:331} WARNING - Malformed experiment 'artifacts'. Detailed error Yaml file '/app/mlruns/artifacts/meta.yaml' does not exist.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 327, in search_experiments
    exp = self._get_experiment(exp_id, view_type)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 421, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 1367, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 1360, in _read_helper
    result = read_yaml(root, file_name)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/file_utils.py", line 309, in read_yaml
    raise MissingConfigException(f"Yaml file '{file_path}' does not exist.")
mlflow.exceptions.MissingConfigException: Yaml file '/app/mlruns/artifacts/meta.yaml' does not exist.
[2025-05-27T12:30:02.443+0000] {logging_mixin.py:188} WARNING - 2025/05/27 12:30:02 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2025-05-27T12:30:02.664+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460 ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
[2025-05-27T12:30:02.772+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å LogisticRegression —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/LogisticRegression.pkl
[2025-05-27T12:30:03.010+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å DecisionTree —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/DecisionTree.pkl
[2025-05-27T12:30:03.454+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å RandomForest —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/RandomForest.pkl
[2025-05-27T12:30:03.467+0000] {python.py:202} INFO - Done. Returned value was: None
[2025-05-27T12:30:03.496+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=train_ml_models, task_id=train_and_log_models, execution_date=20250527T122958, start_date=20250527T123000, end_date=20250527T123003
[2025-05-27T12:30:03.527+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-27T12:30:03.564+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
