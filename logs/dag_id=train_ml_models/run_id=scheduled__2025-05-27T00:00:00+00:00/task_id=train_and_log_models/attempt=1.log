[2025-05-28T00:00:02.660+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T00:00:02.665+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T00:00:02.666+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2025-05-28T00:00:02.674+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): train_and_log_models> on 2025-05-27 00:00:00+00:00
[2025-05-28T00:00:02.684+0000] {standard_task_runner.py:60} INFO - Started process 35868 to run task
[2025-05-28T00:00:02.689+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'train_ml_models', 'train_and_log_models', 'scheduled__2025-05-27T00:00:00+00:00', '--job-id', '93', '--raw', '--subdir', 'DAGS_FOLDER/train_models.py', '--cfg-path', '/tmp/tmprg9ks0vu']
[2025-05-28T00:00:02.691+0000] {standard_task_runner.py:88} INFO - Job 93: Subtask train_and_log_models
[2025-05-28T00:00:02.749+0000] {task_command.py:423} INFO - Running <TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [running]> on host c98d9169a537
[2025-05-28T00:00:02.823+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='train_ml_models' AIRFLOW_CTX_TASK_ID='train_and_log_models' AIRFLOW_CTX_EXECUTION_DATE='2025-05-27T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-27T00:00:00+00:00'
[2025-05-28T00:00:04.625+0000] {logging_mixin.py:188} INFO - üß™ –í—ã–ø–æ–ª–Ω—è–µ–º dvc pull...
[2025-05-28T00:00:04.630+0000] {logging_mixin.py:188} INFO - STDOUT: Everything is up to date.
[2025-05-28T00:00:04.630+0000] {logging_mixin.py:188} INFO - STDERR: 
[2025-05-28T00:00:04.673+0000] {file_store.py:331} WARNING - Malformed experiment 'artifacts'. Detailed error Yaml file '/app/mlruns/artifacts/meta.yaml' does not exist.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 327, in search_experiments
    exp = self._get_experiment(exp_id, view_type)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 421, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 1367, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 1360, in _read_helper
    result = read_yaml(root, file_name)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/file_utils.py", line 309, in read_yaml
    raise MissingConfigException(f"Yaml file '{file_path}' does not exist.")
mlflow.exceptions.MissingConfigException: Yaml file '/app/mlruns/artifacts/meta.yaml' does not exist.
[2025-05-28T00:00:05.022+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460 ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
[2025-05-28T00:00:05.107+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å LogisticRegression —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/LogisticRegression.pkl
[2025-05-28T00:00:05.239+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å DecisionTree —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/DecisionTree.pkl
[2025-05-28T00:00:05.579+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å RandomForest —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/RandomForest.pkl
[2025-05-28T00:00:05.585+0000] {python.py:202} INFO - Done. Returned value was: None
[2025-05-28T00:00:05.616+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=train_ml_models, task_id=train_and_log_models, execution_date=20250527T000000, start_date=20250528T000002, end_date=20250528T000005
[2025-05-28T00:00:05.650+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-28T00:00:05.677+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-28T06:12:13.852+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T06:12:13.892+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T06:12:13.894+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2025-05-28T06:12:13.938+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): train_and_log_models> on 2025-05-27 00:00:00+00:00
[2025-05-28T06:12:14.008+0000] {standard_task_runner.py:60} INFO - Started process 354 to run task
[2025-05-28T06:12:14.017+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'train_ml_models', 'train_and_log_models', 'scheduled__2025-05-27T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/train_models_old.py', '--cfg-path', '/tmp/tmpokos2y63']
[2025-05-28T06:12:14.039+0000] {standard_task_runner.py:88} INFO - Job 2: Subtask train_and_log_models
[2025-05-28T06:12:15.305+0000] {task_command.py:423} INFO - Running <TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [running]> on host c97f03557ca7
[2025-05-28T06:12:15.858+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='train_ml_models' AIRFLOW_CTX_TASK_ID='train_and_log_models' AIRFLOW_CTX_EXECUTION_DATE='2025-05-27T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-27T00:00:00+00:00'
[2025-05-28T06:12:19.160+0000] {logging_mixin.py:188} INFO - üß™ –í—ã–ø–æ–ª–Ω—è–µ–º dvc pull...
[2025-05-28T06:12:19.164+0000] {logging_mixin.py:188} INFO - STDOUT: Everything is up to date.
[2025-05-28T06:12:19.164+0000] {logging_mixin.py:188} INFO - STDERR: 
[2025-05-28T06:12:19.218+0000] {logging_mixin.py:188} WARNING - 2025/05/28 06:12:19 INFO mlflow.tracking.fluent: Experiment with name 'wine-quality' does not exist. Creating a new experiment.
[2025-05-28T06:12:19.987+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460 ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
[2025-05-28T06:12:20.054+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å LogisticRegression —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/LogisticRegression.pkl
[2025-05-28T06:12:20.184+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å DecisionTree —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/DecisionTree.pkl
[2025-05-28T06:12:20.986+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å RandomForest —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/RandomForest.pkl
[2025-05-28T06:12:20.997+0000] {python.py:202} INFO - Done. Returned value was: None
[2025-05-28T06:12:21.032+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=train_ml_models, task_id=train_and_log_models, execution_date=20250527T000000, start_date=20250528T061213, end_date=20250528T061221
[2025-05-28T06:12:21.103+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-28T06:12:21.146+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-28T06:25:40.267+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T06:25:40.275+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T06:25:40.275+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2025-05-28T06:25:40.293+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): train_and_log_models> on 2025-05-27 00:00:00+00:00
[2025-05-28T06:25:40.305+0000] {standard_task_runner.py:60} INFO - Started process 707 to run task
[2025-05-28T06:25:40.310+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'train_ml_models', 'train_and_log_models', 'scheduled__2025-05-27T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/train_models_old.py', '--cfg-path', '/tmp/tmp2s9912fl']
[2025-05-28T06:25:40.320+0000] {standard_task_runner.py:88} INFO - Job 2: Subtask train_and_log_models
[2025-05-28T06:25:40.381+0000] {task_command.py:423} INFO - Running <TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [running]> on host 6b3404098da3
[2025-05-28T06:25:40.445+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='train_ml_models' AIRFLOW_CTX_TASK_ID='train_and_log_models' AIRFLOW_CTX_EXECUTION_DATE='2025-05-27T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-27T00:00:00+00:00'
[2025-05-28T06:25:43.762+0000] {logging_mixin.py:188} INFO - üß™ –í—ã–ø–æ–ª–Ω—è–µ–º dvc pull...
[2025-05-28T06:25:43.768+0000] {logging_mixin.py:188} INFO - STDOUT: Everything is up to date.
[2025-05-28T06:25:43.769+0000] {logging_mixin.py:188} INFO - STDERR: 
[2025-05-28T06:25:45.953+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460 ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
[2025-05-28T06:25:46.374+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å LogisticRegression —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/LogisticRegression.pkl
[2025-05-28T06:25:47.735+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å DecisionTree —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/DecisionTree.pkl
[2025-05-28T06:25:49.279+0000] {logging_mixin.py:188} INFO - ‚úÖ –ú–æ–¥–µ–ª—å RandomForest —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: /app/artifacts/RandomForest.pkl
[2025-05-28T06:25:49.312+0000] {python.py:202} INFO - Done. Returned value was: None
[2025-05-28T06:25:49.370+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=train_ml_models, task_id=train_and_log_models, execution_date=20250527T000000, start_date=20250528T062540, end_date=20250528T062549
[2025-05-28T06:25:49.434+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-28T06:25:49.500+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-28T07:32:09.425+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T07:32:09.445+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [queued]>
[2025-05-28T07:32:09.447+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2025-05-28T07:32:09.477+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): train_and_log_models> on 2025-05-27 00:00:00+00:00
[2025-05-28T07:32:09.522+0000] {standard_task_runner.py:60} INFO - Started process 2161 to run task
[2025-05-28T07:32:09.536+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'train_ml_models', 'train_and_log_models', 'scheduled__2025-05-27T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/train_models.py', '--cfg-path', '/tmp/tmpp_qxpy7f']
[2025-05-28T07:32:09.551+0000] {standard_task_runner.py:88} INFO - Job 2: Subtask train_and_log_models
[2025-05-28T07:32:09.797+0000] {task_command.py:423} INFO - Running <TaskInstance: train_ml_models.train_and_log_models scheduled__2025-05-27T00:00:00+00:00 [running]> on host 6bb48dadf8eb
[2025-05-28T07:32:10.197+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='train_ml_models' AIRFLOW_CTX_TASK_ID='train_and_log_models' AIRFLOW_CTX_EXECUTION_DATE='2025-05-27T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-27T00:00:00+00:00'
[2025-05-28T07:32:12.823+0000] {logging_mixin.py:188} INFO - üß™ –í—ã–ø–æ–ª–Ω—è–µ–º dvc pull...
[2025-05-28T07:32:12.832+0000] {logging_mixin.py:188} INFO - STDOUT: Everything is up to date.
[2025-05-28T07:32:12.832+0000] {logging_mixin.py:188} INFO - STDERR: 
[2025-05-28T07:32:13.674+0000] {migration.py:216} INFO - Context impl PostgresqlImpl.
[2025-05-28T07:32:13.677+0000] {migration.py:219} INFO - Will assume transactional DDL.
[2025-05-28T07:32:13.680+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/train_models.py", line 62, in train_and_log_models
    mlflow.set_experiment("wine-quality")
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 143, in set_experiment
    client = MlflowClient()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/client.py", line 134, in __init__
    self._tracking_client = TrackingServiceClient(final_tracking_uri)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py", line 82, in __init__
    self.store
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py", line 86, in store
    return utils._get_store(self.tracking_uri)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/utils.py", line 208, in _get_store
    return _tracking_store_registry.get_store(store_uri, artifact_uri)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/registry.py", line 42, in get_store
    return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/registry.py", line 52, in _get_store_with_resolved_uri
    return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/utils.py", line 138, in _get_sqlalchemy_store
    return SqlAlchemyStore(store_uri, artifact_uri)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/tracking/sqlalchemy_store.py", line 180, in __init__
    mlflow.store.db.utils._verify_schema(self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/db/utils.py", line 119, in _verify_schema
    raise MlflowException(
mlflow.exceptions.MlflowException: Detected out-of-date database schema (found version 0584bdc529eb, but expected f5a4f2784254). Take a backup of your database, then run 'mlflow db upgrade <database_uri>' to migrate your database to the latest schema. NOTE: schema migration may result in database downtime - please consult your database's documentation for more detail.
[2025-05-28T07:32:13.698+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=train_ml_models, task_id=train_and_log_models, execution_date=20250527T000000, start_date=20250528T073209, end_date=20250528T073213
[2025-05-28T07:32:13.715+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 2 for task train_and_log_models (Detected out-of-date database schema (found version 0584bdc529eb, but expected f5a4f2784254). Take a backup of your database, then run 'mlflow db upgrade <database_uri>' to migrate your database to the latest schema. NOTE: schema migration may result in database downtime - please consult your database's documentation for more detail.; 2161)
[2025-05-28T07:32:13.748+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-05-28T07:32:13.796+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
